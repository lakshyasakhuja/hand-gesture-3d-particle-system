# Hand-Gesture Controlled 3D Particle System (AI + Computer Vision)

This repository contains a **personal AI-powered interactive graphics project**, combining **real-time hand-tracking**, **3D particle simulation**, and **gesture-based control** using modern web technologies.

The project uses **AI computer vision models** to interpret hand gestures from a webcam and translate them into dynamic transformations of a **3D particle system**, creating an immersive, real-time humanâ€“computer interaction experience.

---

## ğŸ“˜ Project Overview

This project explores how **AI perception models** can be integrated with **real-time graphics engines** to create natural, intuitive interaction systems.

Using a live webcam feed, the system tracks hand landmarks in real time and maps gestures to visual transformations such as:

- Morphing between complex 3D shapes  
- Expanding and contracting particle structures  
- Rotating and colouring particle systems dynamically  

The result is an interactive, responsive 3D environment controlled entirely through **hand gestures**, without any physical controllers.

---

## ğŸ§  Core Concepts & Motivation

Traditional user interfaces rely heavily on keyboards, mice, or touch input. This project was motivated by the question:

> *How can AI-driven perception enable more natural, embodied forms of interaction?*

By combining **computer vision**, **gesture recognition**, and **3D graphics**, this project demonstrates how AI can bridge the gap between physical movement and digital environments â€” a key concept in areas such as:
- Humanâ€“Computer Interaction (HCI)  
- Creative AI  
- AR/VR interfaces  
- Interactive visualisation  

---

## ğŸ–ï¸ AI Hand-Tracking & Gesture Control

The system uses **MediaPipe Hands**, an AI-based hand-tracking model, to detect and track 21 hand landmarks in real time.

Recognised gestures and mappings include:

- âœŒï¸ **Victory / Peace sign** â†’ Cycle through 3D shapes  
- ğŸ‘Œ **Pinch gesture** â†’ Expand or contract particle structures  
- âœŠ **Fist gesture** â†’ Collapse particles toward the core  
- Hand position (X/Y) â†’ Control rotation speed and colour gradients  

Gesture logic is implemented with debouncing to ensure smooth, intentional interaction.

---

## ğŸŒŒ 3D Particle System & Shape Morphing

The visual system is built using **Three.js**, rendering **12,000+ particles** in real time.

Particles dynamically morph between mathematically defined 3D shapes, including:

- Sphere  
- Heart (parametric curve)  
- Saturn-style planet with rings  
- Flower / rose curve  
- Torus  

Particles interpolate smoothly between target positions, creating fluid transitions rather than abrupt shape changes.

---

## âš™ï¸ Technical Architecture

The project is implemented as a **single-file, self-contained web application**, making it easy to run locally or deploy.

Key components:
- **MediaPipe Hands** â†’ AI hand landmark detection  
- **Three.js** â†’ 3D rendering and animation  
- **WebGL** â†’ GPU-accelerated particle rendering  
- **JavaScript (ES Modules)** â†’ Real-time logic and animation loop  

The architecture cleanly separates:
- AI perception  
- Gesture interpretation  
- Visual transformation  
- Rendering and animation  

---

## ğŸ“‚ Repository Structure

```text
hand-gesture-3d-particles/
â”œâ”€â”€ index.html
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ demo_images/
â”œâ”€â”€ README.md
````

The entire application runs directly from `index.html` â€” no build tools or frameworks required.

---

## ğŸ§  Key Learnings

* Integrating AI perception models into real-time systems
* Mapping noisy sensor data to stable interactive controls
* Designing gesture-based interaction logic
* Optimising GPU-based particle systems
* Combining mathematics, graphics, and AI into a cohesive system

---

## ğŸ›  Tools & Technologies

* **JavaScript (ES6+)**
* **Three.js**
* **MediaPipe Hands**
* **WebGL**
* **Computer Vision**
* **AI-based Gesture Recognition**
* **Creative Coding & Interactive Systems**

---

## ğŸ“ Significance

This project represents a **self-directed exploration** at the intersection of:

* Artificial Intelligence
* Real-time graphics
* Humanâ€“Computer Interaction

It demonstrates the ability to:

* Design interactive systems from first principles
* Work directly with AI models rather than abstractions
* Build visually compelling, technically complex applications

This is my **most experimental and technically expressive project** to date.